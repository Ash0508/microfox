## Function: `models.generate_content`

Generates content using the specified Gemini model and configuration, including optional code execution.

**Purpose:**
This function allows you to generate text and code using a Gemini model. It supports enabling a code execution tool, which allows the model to generate and run Python code, learn from the results, and incorporate them into the final output.

**Parameters:**

- `model` (string, required): The name of the Gemini model to use (e.g., "gemini-2.0-flash"). All Gemini 2.0 models support code execution.
- `contents` (string, required): The input prompt or query for the model. This is the text that the model will use to generate a response.
- `config` (GenerateContentConfig object, required): Configuration settings for content generation.

  - `tools` (array<Tool object>, optional): An array of tools to enable for the model.

    - `code_execution` (ToolCodeExecution object, optional): Configures the code execution tool. When present, the model can generate and execute Python code. No specific fields are required within this object; its presence alone enables code execution.

**Return Value:**

- `response` (object): An object containing the generated content and other information.

  - `candidates` (array<object>): An array of candidate responses. Each candidate is an object with the following structure:

    - `content` (object): The generated content.

      - `parts` (array<object>): An array of content parts. Each part can be one of the following types:

        - `text` (string, optional): Inline text generated by the model.
        - `executable_code` (object, optional): Code generated by the model.

          - `code` (string): The generated code.

        - `code_execution_result` (object, optional): The result of executing the code.

          - `output` (string): The output of the code execution.

**Examples:**

```typescript
// Example 1: Minimal usage with code execution
import {
  Client,
  GenerateContentConfig,
  Tool,
  ToolCodeExecution,
} from '@google/genai';

const client = new Client();

const response = client.models.generate_content({
  model: 'gemini-2.0-flash',
  contents:
    'What is the sum of the first 50 prime numbers? Generate and run code for the calculation, and make sure you get all 50.',
  config: new GenerateContentConfig({
    tools: [new Tool({ code_execution: new ToolCodeExecution() })],
  }),
});

for (const part of response.candidates[0].content.parts) {
  if (part.text) {
    console.log(part.text);
  }
  if (part.executable_code) {
    console.log(part.executable_code.code);
  }
  if (part.code_execution_result) {
    console.log(part.code_execution_result.output);
  }
}

// Example 2: Without code execution
import { Client, GenerateContentConfig } from '@google/genai';

const client = new Client();

const response = client.models.generate_content({
  model: 'gemini-2.0-flash',
  contents: 'What is the sum of the first 50 prime numbers?',
  config: new GenerateContentConfig(), // No tools specified
});

console.log(response.candidates[0].content.parts[0].text); // Assuming the response is simple text

// Example 3: Handling potential undefined values
import {
  Client,
  GenerateContentConfig,
  Tool,
  ToolCodeExecution,
} from '@google/genai';

const client = new Client();

const response = client.models.generate_content({
  model: 'gemini-2.0-flash',
  contents: 'Tell me a story.', // May or may not include code execution based on model's decision
  config: new GenerateContentConfig({
    tools: [new Tool({ code_execution: new ToolCodeExecution() })],
  }),
});

for (const part of response.candidates[0].content.parts) {
  console.log(part.text ?? ''); // Handle potentially undefined text
  console.log(part.executable_code?.code ?? ''); // Handle potentially undefined code
  console.log(part.code_execution_result?.output ?? ''); // Handle potentially undefined output
}
```

## Function: `chats.create`

Creates a new chat session with the specified model and configuration, including optional code execution.

**Purpose:**
This function initiates a chat session, allowing for interactive conversations with the model. It supports enabling a code execution tool within the chat, enabling the model to generate and run Python code as part of the conversation.

**Parameters:**

- `model` (string, required): The name of the Gemini model to use (e.g., "gemini-2.0-flash"). All Gemini 2.0 models support code execution within a chat.
- `config` (GenerateContentConfig object, required): Configuration settings for the chat session.

  - `tools` (array<Tool object>, optional): An array of tools to enable for the chat.

    - `code_execution` (ToolCodeExecution object, optional): Configures the code execution tool. When present, the model can generate and execute Python code within the chat. No specific fields are required within this object; its presence alone enables code execution.

**Return Value:**

- `chat` (object): A chat object that can be used to send and receive messages. This object has the following methods:

  - `send_message(message: string)`: Sends a message to the chat. Returns a response object similar to the `models.generate_content` function, containing the model's reply, including potential code and execution results.

**Examples:**

```typescript
// Example 1: Creating a chat with code execution and sending a message
import {
  Client,
  GenerateContentConfig,
  Tool,
  ToolCodeExecution,
} from '@google/genai';

const client = new Client();

const chat = client.chats.create({
  model: 'gemini-2.0-flash',
  config: new GenerateContentConfig({
    tools: [new Tool({ code_execution: new ToolCodeExecution() })],
  }),
});

const response = chat.send_message(
  'What is the sum of the first 50 prime numbers? Generate and run code for the calculation.',
);

for (const part of response.candidates[0].content.parts) {
  if (part.text) {
    console.log(part.text);
  }
  if (part.executable_code) {
    console.log(part.executable_code.code);
  }
  if (part.code_execution_result) {
    console.log(part.code_execution_result.output);
  }
}

// Example 2: Creating a chat without code execution
import { Client, GenerateContentConfig } from '@google/genai';

const client = new Client();

const chat = client.chats.create({
  model: 'gemini-2.0-flash',
  config: new GenerateContentConfig(), // No tools specified
});

const response = chat.send_message('Tell me a story.');
console.log(response.candidates[0].content.parts[0].text); // Assuming the response is simple text
```

## Environment Variables

- **GOOGLE_API_KEY** (required): Your Google API key. This is required for authenticating with the Gemini API.

## Additional Notes on Code Execution

- **File I/O:** Code execution supports file input (CSV, text) and graph output (Matplotlib). File input is subject to size limits.
- **Libraries:** Several Python libraries are available in the code execution environment, including `numpy`, `pandas`, `matplotlib`, and others. You cannot install custom libraries.
- **Limitations:** The model can only execute Python code. Enabling code execution might affect performance in other areas. There are limitations on runtime and file sizes.
- **Billing:** You are billed for input and output tokens, including generated code and execution results. There is no additional charge for enabling code execution itself.

This documentation provides a comprehensive guide to using code execution with the Gemini API, covering both single requests and chat sessions. Remember to handle potential undefined values in the response and be mindful of the limitations and billing details.
