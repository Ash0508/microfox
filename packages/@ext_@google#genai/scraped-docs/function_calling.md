{
  "url": "https://ai.google.dev/gemini-api/docs/function-calling",
  "content": "Skip to main content\nSign in\nModels\nMore\nGemini API docs\nAPI Reference\nCookbook\nCommunity\nSolutions\nMore\nCode assistance\nMore\nShowcase\nMore\nCommunity\nMore\nGet started\nOverview\nQuickstart\nAPI keys\nLibraries\nOpenAI compatibility\nModels\nAll models\nPricing\nRate limits\nBilling info\nModel Capabilities\nText generation\nImage generation\nVideo generation\nLong context\nStructured output\nThinking\nFunction calling\nDocument understanding\nImage understanding\nVideo understanding\nAudio understanding\nCode execution\nGrounding with Google Search\nGuides\nPrompt engineering\nLive API\nContext caching\nFiles API\nToken counting\nFine-tuning\nEmbeddings\nSafety\nResources\nMigrate to Gen AI SDK\nRelease notes\nAPI troubleshooting\nAI Studio\nCloud\nPolicies\nTerms of service\nAvailable regions\nAdditional usage polices\nIntroducing Gemini 2.5 Flash, Veo 2, and updates to the Live API Learn more\nHome\nGemini API\nModels\nWas this helpful?\nSend feedback\nFunction Calling with the Gemini API\nOn this page\nHow Function Calling Works\nStep 1: Define Function Declaration\nStep 2: Call the model with function declarations\nStep 3: Execute set_light_values function code\nStep 4: Create User friendly response with function result and call the model again\n\nFunction calling lets you connect models to external tools and APIs. Instead of generating text responses, the model understands when to call specific functions and provides the necessary parameters to execute real-world actions. This allows the model to act as a bridge between natural language and real-world actions and data. Function calling has 3 primary use cases:\n\nAugment Knowledge: Access information from external sources like databases, APIs, and knowledge bases.\nExtend Capabilities: Use external tools to perform computations and extend the limitations of the model, such as using a calculator or creating charts.\nTake Actions: Interact with external systems using APIs, such as scheduling appointments, creating invoices, sending emails, or controlling smart home devices\n\nGet Weather Schedule Meeting Create Chart\n\nHow Function Calling Works\n\nFunction calling involves a structured interaction between your application, the model, and external functions. Here's a breakdown of the process:\n\nDefine Function Declaration: Define the function declaration in your application code. Function Declarations describe the function's name, parameters, and purpose to the model.\nCall LLM with function declarations: Send user prompt along with the function declaration(s) to the model. It analyzes the request and determines if a function call would be helpful. If so, it responds with a structured JSON object.\nExecute Function Code (Your Responsibility): The Model does not execute the function itself. It's your application's responsibility to process the response and check for Function Call, if\nYes: Extract the name and args of the function and execute the corresponding function in your application.\nNo: The model has provided a direct text response to the prompt (this flow is less emphasized in the example but is a possible outcome).\nCreate User friendly response: If a function was executed, capture the result and send it back to the model in a subsequent turn of the conversation. It will use the result to generate a final, user-friendly response that incorporates the information from the function call.\n\nThis process can be repeated over multiple turns, allowing for complex interactions and workflows. The model also supports calling multiple functions in a single turn (parallel function calling) and in sequence (compositional function calling).\n\nStep 1: Define Function Declaration\n\nDefine a function and its declaration within your application code that allows users to set light values and make an API request. This function could call external services or APIs.\n\nPython\nJavaScript\nfrom google.genai import types\n\n# Define a function that the model can call to control smart lights\nset_light_values_declaration = {\n    \"name\": \"set_light_values\",\n    \"description\": \"Sets the brightness and color temperature of a light.\",\n    \"parameters\": {\n        \"type\": \"object\",\n        \"properties\": {\n            \"brightness\": {\n                \"type\": \"integer\",\n                \"description\": \"Light level from 0 to 100. Zero is off and 100 is full brightness\",\n            },\n            \"color_temp\": {\n                \"type\": \"string\",\n                \"enum\": [\"daylight\", \"cool\", \"warm\"],\n                \"description\": \"Color temperature of the light fixture, which can be `daylight`, `cool` or `warm`.\",\n            },\n        },\n        \"required\": [\"brightness\", \"color_temp\"],\n    },\n}\n\n# This is the actual function that would be called based on the model's suggestion\ndef set_light_values(brightness: int, color_temp: str) -> dict[str, int | str]:\n    \"\"\"Set the brightness and color temperature of a room light. (mock API).\n\n    Args:\n        brightness: Light level from 0 to 100. Zero is off and 100 is full brightness\n        color_temp: Color temperature of the light fixture, which can be `daylight`, `cool` or `warm`.\n\n    Returns:\n        A dictionary containing the set brightness and color temperature.\n    \"\"\"\n    return {\"brightness\": brightness, \"colorTemperature\": color_temp}\n\n\nStep 2: Call the model with function declarations\n\nOnce you have defined your function declarations, you can prompt the model to use the function. It analyzes the prompt and function declarations and decides to respond directly or to call a function. If a function is called the response object will contain a function call suggestion.\n\nPython\nJavaScript\nfrom google import genai\n\n# Generation Config with Function Declaration\ntools = types.Tool(function_declarations=[set_light_values_declaration])\nconfig = types.GenerateContentConfig(tools=[tools])\n\n# Configure the client\nclient = genai.Client(api_key=os.getenv(\"GEMINI_API_KEY\"))\n\n# Define user prompt\ncontents = [\n    types.Content(\n        role=\"user\", parts=[types.Part(text=\"Turn the lights down to a romantic level\")]\n    )\n]\n\n# Send request with function declarations\nresponse = client.models.generate_content(\n    model=\"gemini-2.0-flash\", config=config, contents=contents\n)\n\nprint(response.candidates[0].content.parts[0].function_call)\n\n\nThe model then returns a functionCall object in an OpenAPI compatible schema specifying how to call one or more of the declared functions in order to respond to the user's question.\n\nPython\nJavaScript\nid=None args={'color_temp': 'warm', 'brightness': 25} name='set_light_values'\n\nStep 3: Execute set_light_values function code\n\nExtract the function call details from the model's response, parse the arguments , and execute the set_light_values function in our code.\n\nPython\nJavaScript\n# Extract tool call details\ntool_call = response.candidates[0].content.parts[0].function_call\n\nif tool_call.name == \"set_light_values\":\n    result = set_light_values(**tool_call.args)\n    print(f\"Function execution result: {result}\")\n\nStep 4: Create User friendly response with function result and call the model again\n\nFinally, send the result of the function execution back to the model so it can incorporate this information into its final response to the user.\n\nPython\nJavaScript\n# Create a function response part\nfunction_response_part = types.Part.from_function_response(\n    name=tool_call.name,\n    response={\"result\": result},\n)\n\n# Append function call and result of the function execution to contents\ncontents.append(types.Content(role=\"model\", parts=[types.Part(function_call=tool_call)])) # Append the model's function call message\ncontents.append(types.Content(role=\"user\", parts=[function_response_part])) # Append the function response\n\nfinal_response = client.models.generate_content(\n    model=\"gemini-2.0-flash\",\n    config=config,\n    contents=contents,\n)\n\nprint(final_response.text)\n\n\nThis completes the function calling flow. The Model successfully used the set_light_values function to perform the request action of the user.\n\nFunction declarations\n\nWhen you implement function calling in a prompt, you create a tools object, which contains one or more function declarations. You define functions using JSON, specifically with a select subset of the OpenAPI schema format. A single function declaration can include the following parameters:\n\nname (string): A unique name for the function (get_weather_forecast, send_email). Use descriptive names without spaces or special characters (use underscores or camelCase).\ndescription (string): A clear and detailed explanation of the function's purpose and capabilities. This is crucial for the model to understand when to use the function. Be specific and provide examples if helpful (\"Finds theaters based on location and optionally movie title which is currently playing in theaters.\").\nparameters (object): Defines the input parameters the function expects.\ntype (string): Specifies the overall data type, such as object.\nproperties (object): Lists individual parameters, each with:\ntype (string): The data type of the parameter, such as string, integer, boolean, array.\ndescription (string): A description of the parameter's purpose and format. Provide examples and constraints (\"The city and state, e.g., 'San Francisco, CA' or a zip code e.g., '95616'.\").\nenum (array, optional): If the parameter values are from a fixed set, use \"enum\" to list the allowed values instead of just describing them in the description. This improves accuracy (\"enum\": [\"daylight\", \"cool\", \"warm\"]).\nrequired (array): An array of strings listing the parameter names that are mandatory for the function to operate.\nParallel Function Calling\n\nIn addition to single turn function calling, you can also call multiple functions at once. Parallel function calling lets you execute multiple functions at once and is used when the functions are not dependent on each other. This is useful in scenarios like gathering data from multiple independent sources, such as retrieving customer details from different databases or checking inventory levels across various warehouses or performing multiple actions such as converting your apartment into a disco.\n\nPython\nJavaScript\npower_disco_ball = {\n    \"name\": \"power_disco_ball\",\n    \"description\": \"Powers the spinning disco ball.\",\n    \"parameters\": {\n        \"type\": \"object\",\n        \"properties\": {\n            \"power\": {\n                \"type\": \"boolean\",\n                \"description\": \"Whether to turn the disco ball on or off.\",\n            }\n        },\n        \"required\": [\"power\"],\n    },\n}\n\nstart_music = {\n    \"name\": \"start_music\",\n    \"description\": \"Play some music matching the specified parameters.\",\n    \"parameters\": {\n        \"type\": \"object\",\n        \"properties\": {\n            \"energetic\": {\n                \"type\": \"boolean\",\n                \"description\": \"Whether the music is energetic or not.\",\n            },\n            \"loud\": {\n                \"type\": \"boolean\",\n                \"description\": \"Whether the music is loud or not.\",\n            },\n        },\n        \"required\": [\"energetic\", \"loud\"],\n    },\n}\n\ndim_lights = {\n    \"name\": \"dim_lights\",\n    \"description\": \"Dim the lights.\",\n    \"parameters\": {\n        \"type\": \"object\",\n        \"properties\": {\n            \"brightness\": {\n                \"type\": \"number\",\n                \"description\": \"The brightness of the lights, 0.0 is off, 1.0 is full.\",\n            }\n        },\n        \"required\": [\"brightness\"],\n    },\n}\n\n\nCall the model with an instruction that could use all of the specified tools. This example uses a tool_config. To learn more you can read about configuring function calling.\n\nPython\nJavaScript\nfrom google import genai\nfrom google.genai import types\n\n# Set up function declarations\nhouse_tools = [\n    types.Tool(function_declarations=[power_disco_ball, start_music, dim_lights])\n]\n\nconfig = {\n    \"tools\": house_tools,\n    \"automatic_function_calling\": {\"disable\": True},\n    # Force the model to call 'any' function, instead of chatting.\n    \"tool_config\": {\"function_calling_config\": {\"mode\": \"any\"}},\n}\n\n# Configure the client\nclient = genai.Client(api_key=os.getenv(\"GEMINI_API_KEY\"))\n\nchat = client.chats.create(model=\"gemini-2.0-flash\", config=config)\nresponse = chat.send_message(\"Turn this place into a party!\")\n\n# Print out each of the function calls requested from this single call\nprint(\"Example 1: Forced function calling\")\nfor fn in response.function_calls:\n    args = \", \".join(f\"{key}={val}\" for key, val in fn.args.items())\n    print(f\"{fn.name}({args})\")\n\n\nEach of the printed results reflects a single function call that the model has requested. To send the results back, include the responses in the same order as they were requested.\n\nThe Python SDK supports a feature called automatic function calling which converts the Python function to declarations, handles the function call execution and response cycle for you. Following is an example for our disco use case.\n\nNote: Automatic Function Calling is a Python SDK only feature at the moment.\nPython\nfrom google import genai\nfrom google.genai import types\n\n# Actual implementation functions\ndef power_disco_ball_impl(power: bool) -> dict:\n    \"\"\"Powers the spinning disco ball.\n\n    Args:\n        power: Whether to turn the disco ball on or off.\n\n    Returns:\n        A status dictionary indicating the current state.\n    \"\"\"\n    return {\"status\": f\"Disco ball powered {'on' if power else 'off'}\"}\n\ndef start_music_impl(energetic: bool, loud: bool) -> dict:\n    \"\"\"Play some music matching the specified parameters.\n\n    Args:\n        energetic: Whether the music is energetic or not.\n        loud: Whether the music is loud or not.\n\n    Returns:\n        A dictionary containing the music settings.\n    \"\"\"\n    music_type = \"energetic\" if energetic else \"chill\"\n    volume = \"loud\" if loud else \"quiet\"\n    return {\"music_type\": music_type, \"volume\": volume}\n\ndef dim_lights_impl(brightness: float) -> dict:\n    \"\"\"Dim the lights.\n\n    Args:\n        brightness: The brightness of the lights, 0.0 is off, 1.0 is full.\n\n    Returns:\n        A dictionary containing the new brightness setting.\n    \"\"\"\n    return {\"brightness\": brightness}\n\nconfig = {\n    \"tools\": [power_disco_ball_impl, start_music_impl, dim_lights_impl],\n}\n\nchat = client.chats.create(model=\"gemini-2.0-flash\", config=config)\nresponse = chat.send_message(\"Do everything you need to this place into party!\")\n\nprint(\"\\nExample 2: Automatic function calling\")\nprint(response.text)\n# I've turned on the disco ball, started playing loud and energetic music, and dimmed the lights to 50% brightness. Let's get this party started!\n\nCompositional Function Calling\n\nGemini 2.0 supports compositional function calling, meaning the model can chain multiple function calls together. For example, to answer \"Get the temperature in my current location\", the Gemini API might invoke both a get_current_location() function and a get_weather() function that takes the location as a parameter.\n\nNote: Compositional function calling is a Live API only feature at the moment. The run() function declaration, which handles the asynchronous websocket setup, is omitted for brevity.\nPython\nJavaScript\n# Light control schemas\nturn_on_the_lights_schema = {'name': 'turn_on_the_lights'}\nturn_off_the_lights_schema = {'name': 'turn_off_the_lights'}\n\nprompt = \"\"\"\n  Hey, can you write run some python code to turn on the lights, wait 10s and then turn off the lights?\n  \"\"\"\n\ntools = [\n    {'code_execution': {}},\n    {'function_declarations': [turn_on_the_lights_schema, turn_off_the_lights_schema]}\n]\n\nawait run(prompt, tools=tools, modality=\"AUDIO\")\n\nFunction calling modes\n\nThe Gemini API lets you control how the model uses the provided tools (function declarations). Specifically, you can set the mode within the function_calling_config.\n\nAUTO (Default): The model decides whether to generate a natural language response or suggest a function call based on the prompt and context. This is the most flexible mode and recommended for most scenarios.\nANY: The model is constrained to always predict a function call and guarantee function schema adherence. If allowed_function_names is not specified, the model can choose from any of the provided function declarations. If allowed_function_names is provided as a list, the model can only choose from the functions in that list. Use this mode when you require a function call in response to every prompt (if applicable).\n\nNONE: The model is prohibited from making function calls. This is equivalent to sending a request without any function declarations. Use this to temporarily disable function calling without removing your tool definitions.\n\nPython\nJavaScript\nfrom google.genai import types\n\n# Configure function calling mode\ntool_config = types.ToolConfig(\n    function_calling_config=types.FunctionCallingConfig(\n        mode=\"ANY\", allowed_function_names=[\"get_current_temperature\"]\n    )\n)\n\n# Create the generation config\nconfig = types.GenerateContentConfig(\n    temperature=0,\n    tools=[tools],  # not defined here.\n    tool_config=tool_config,\n)\n\nAutomatic Function Calling (Python Only)\n\nWhen using the Python SDK, you can provide Python functions directly as tools. The SDK automatically converts the Python function to declarations, handles the function call execution and response cycle for you. The Python SDK then automatically:\n\nDetects function call responses from the model.\nCall the corresponding Python function in your code.\nSends the function response back to the model.\nReturns the model's final text response.\n\nTo use this, define your function with type hints and a docstring, and then pass the function itself (not a JSON declaration) as a tool:\n\nPython\nfrom google import genai\nfrom google.genai import types\n\n# Define the function with type hints and docstring\ndef get_current_temperature(location: str) -> dict:\n    \"\"\"Gets the current temperature for a given location.\n\n    Args:\n        location: The city and state, e.g. San Francisco, CA\n\n    Returns:\n        A dictionary containing the temperature and unit.\n    \"\"\"\n    # ... (implementation) ...\n    return {\"temperature\": 25, \"unit\": \"Celsius\"}\n\n# Configure the client and model\nclient = genai.Client(api_key=os.getenv(\"GEMINI_API_KEY\"))  # Replace with your actual API key setup\nconfig = types.GenerateContentConfig(\n    tools=[get_current_temperature]\n)  # Pass the function itself\n\n# Make the request\nresponse = client.models.generate_content(\n    model=\"gemini-2.0-flash\",\n    contents=\"What's the temperature in Boston?\",\n    config=config,\n)\n\nprint(response.text)  # The SDK handles the function call and returns the final text\n\n\nYou can disable automatic function calling with:\n\nPython\n# To disable automatic function calling:\nconfig = types.GenerateContentConfig(\n    tools=[get_current_temperature],\n    automatic_function_calling=types.AutomaticFunctionCallingConfig(disable=True)\n)\n\nAutomatic Function schema declaration\n\nAutomatic schema extraction from Python functions doesn't work in all cases. For example: it doesn't handle cases where you describe the fields of a nested dictionary-object. The API is able to describe any of the following types:\n\nPython\nAllowedType = (int | float | bool | str | list['AllowedType'] | dict[str, AllowedType])\n\n\nTo see what the inferred schema looks like, you can convert it using from_callable:\n\nPython\ndef multiply(a: float, b: float):\n    \"\"\"Returns a * b.\"\"\"\n    return a * b\n\nfn_decl = types.FunctionDeclaration.from_callable(callable=multiply, client=client)\n\n# to_json_dict() provides a clean JSON representation.\nprint(fn_decl.to_json_dict())\n\nMulti-tool use: Combine Native Tools with Function Calling\n\nWith Gemini 2.0, you can enable multiple tools combining native tools with function calling at the same time. Here's an example that enables two tools, Grounding with Google Search and code execution, in a request using the Live API.\n\nNote: Multi-tool use is a Live API only feature at the moment. The run() function declaration, which handles the asynchronous websocket setup, is omitted for brevity.\nPython\nJavaScript\n\n# Multiple tasks example - combining lights, code execution, and search\nprompt = \"\"\"\n  Hey, I need you to do three things for me.\n\n    1.  Turn on the lights.\n    2.  Then compute the largest prime palindrome under 100000.\n    3.  Then use Google Search to look up information about the largest earthquake in California the week of Dec 5 2024.\n\n  Thanks!\n  \"\"\"\n\ntools = [\n    {'google_search': {}},\n    {'code_execution': {}},\n    {'function_declarations': [turn_on_the_lights_schema, turn_off_the_lights_schema]} # not defined here.\n]\n\n# Execute the prompt with specified tools in audio modality\nawait run(prompt, tools=tools, modality=\"AUDIO\")\n\n\nPython developers can try this out in the Live API Tool Use notebook.\n\nUse Model Context Protocol (MCP)\n\nModel Context Protocol (MCP) is an open standard to connect AI applications with external tools, data sources, and systems. MCP provides a common protocol for models to access context, such as functions (tools), data sources (resources), or predefined prompts. You can use models with MCP server using their tool calling capabilities.\n\nMCP servers expose the tools as JSON schema definitions, which can be used with Gemini compatible function declarations. This lets you to use a MCP server with Gemini models directly. Here, you can find an example of how to use a local MCP server with Gemini SDK and the mcp SDK.\n\nPython\nJavaScript\nimport asyncio\nimport os\nfrom datetime import datetime\nfrom google import genai\nfrom google.genai import types\nfrom mcp import ClientSession, StdioServerParameters\nfrom mcp.client.stdio import stdio_client\n\nclient = genai.Client(api_key=os.getenv(\"GEMINI_API_KEY\"))\n\n# Create server parameters for stdio connection\nserver_params = StdioServerParameters(\n    command=\"npx\",  # Executable\n    args=[\"-y\", \"@philschmid/weather-mcp\"],  # Weather MCP Server\n    env=None,  # Optional environment variables\n)\n\nasync def run():\n    async with stdio_client(server_params) as (read, write):\n        async with ClientSession(read, write) as session:\n            # Prompt to get the weather for the current day in London.\n            prompt = f\"What is the weather in London in {datetime.now().strftime('%Y-%m-%d')}?\"\n            # Initialize the connection between client and server\n            await session.initialize()\n\n            # Get tools from MCP session and convert to Gemini Tool objects\n            mcp_tools = await session.list_tools()\n            tools = [\n                types.Tool(\n                    function_declarations=[\n                        {\n                            \"name\": tool.name,\n                            \"description\": tool.description,\n                            \"parameters\": {\n                                k: v\n                                for k, v in tool.inputSchema.items()\n                                if k not in [\"additionalProperties\", \"$schema\"]\n                            },\n                        }\n                    ]\n                )\n                for tool in mcp_tools.tools\n            ]\n\n            # Send request to the model with MCP function declarations\n            response = client.models.generate_content(\n                model=\"gemini-2.0-flash\",\n                contents=prompt,\n                config=types.GenerateContentConfig(\n                    temperature=0,\n                    tools=tools,\n                ),\n            )\n\n            # Check for a function call\n            if response.candidates[0].content.parts[0].function_call:\n                function_call = response.candidates[0].content.parts[0].function_call\n                print(function_call)\n                # Call the MCP server with the predicted tool\n                result = await session.call_tool(\n                    function_call.name, arguments=function_call.args\n                )\n                print(result.content[0].text)\n                # Continue as shown in step 4 of \"How Function Calling Works\"\n                # and create a user friendly response\n            else:\n                print(\"No function call found in the response.\")\n                print(response.text)\n\n# Start the asyncio event loop and run the main function\nasyncio.run(run())\n\nSupported Models\n\nExperimental models are not included. You can find their capabilities on the model overview page.\n\nModel\tFunction Calling\tParallel Function Calling\tCompositional Function Calling\n(Live API only)\nGemini 2.0 Flash\t✔️\t✔️\t✔️\nGemini 2.0 Flash-Lite\tX\tX\tX\nGemini 1.5 Flash\t✔️\t✔️\t✔️\nGemini 1.5 Pro\t✔️\t✔️\t✔️\nBest Practices\nFunction and Parameter Descriptions: Be extremely clear and specific in your descriptions. The model relies on these to choose the correct function and provide appropriate arguments.\nNaming: Use descriptive function names (without spaces, periods, or dashes).\nStrong Typing: Use specific types (integer, string, enum) for parameters to reduce errors. If a parameter has a limited set of valid values, use an enum.\nTool Selection: While the model can use an arbitrary number of tools, providing too many can increase the risk of selecting an incorrect or suboptimal tool. For best results, aim to provide only the relevant tools for the context or task, ideally keeping the active set to a maximum of 10-20. Consider dynamic tool selection based on conversation context if you have a large total number of tools.\nPrompt Engineering:\nProvide context: Tell the model its role (e.g., \"You are a helpful weather assistant.\").\nGive instructions: Specify how and when to use functions (e.g., \"Don't guess dates; always use a future date for forecasts.\").\nEncourage clarification: Instruct the model to ask clarifying questions if needed.\nTemperature: Use a low temperature (e.g., 0) for more deterministic and reliable function calls.\nValidation: If a function call has significant consequences (e.g., placing an order), validate the call with the user before executing it.\nError Handling: Implement robust error handling in your functions to gracefully handle unexpected inputs or API failures. Return informative error messages that the model can use to generate helpful responses to the user.\nSecurity: Be mindful of security when calling external APIs. Use appropriate authentication and authorization mechanisms. Avoid exposing sensitive data in function calls.\nToken Limits: Function descriptions and parameters count towards your input token limit. If you're hitting token limits, consider limiting the number of functions or the length of the descriptions, break down complex tasks into smaller, more focused function sets.\nNotes and Limitations\nOnly a subset of the OpenAPI schema is supported.\nSupported parameter types in Python are limited.\nAutomatic function calling is a Python SDK feature only.\nWas this helpful?\nSend feedback\n\nExcept as otherwise noted, the content of this page is licensed under the Creative Commons Attribution 4.0 License, and code samples are licensed under the Apache 2.0 License. For details, see the Google Developers Site Policies. Java is a registered trademark of Oracle and/or its affiliates.\n\nLast updated 2025-04-14 UTC.\n\nTerms\nPrivacy",
  "updatedAt": "2025-05-13T03:14:31.634Z"
}