{
  "url": "https://ai.google.dev/gemini-api/docs/embeddings",
  "content": "Skip to main content\nSign in\nModels\nMore\nGemini API docs\nAPI Reference\nCookbook\nCommunity\nSolutions\nMore\nCode assistance\nMore\nShowcase\nMore\nCommunity\nMore\nGet started\nOverview\nQuickstart\nAPI keys\nLibraries\nOpenAI compatibility\nModels\nAll models\nPricing\nRate limits\nBilling info\nModel Capabilities\nText generation\nImage generation\nVideo generation\nLong context\nStructured output\nThinking\nFunction calling\nDocument understanding\nImage understanding\nVideo understanding\nAudio understanding\nCode execution\nGrounding with Google Search\nGuides\nPrompt engineering\nLive API\nContext caching\nFiles API\nToken counting\nFine-tuning\nEmbeddings\nSafety\nResources\nMigrate to Gen AI SDK\nRelease notes\nAPI troubleshooting\nAI Studio\nCloud\nPolicies\nTerms of service\nAvailable regions\nAdditional usage polices\nIntroducing Gemini 2.5 Flash, Veo 2, and updates to the Live API Learn more\nHome\nGemini API\nModels\nSend feedback\nEmbeddings\nOn this page\nWhat are embeddings?\nGenerate embeddings\nTask types\nSupported task types\nUse cases\nEmbedding models\nWhat's next\n\nNote: Introducing our first Gemini embedding model, available now to developers as gemini-embedding-exp-03-07 in the API.\n\nThe Gemini API supports several embedding models that generate embeddings for words, phrases, code, and sentences. The resulting embeddings can then be used for tasks such as semantic search, text classification, and clustering, among many others.\n\nWhat are embeddings?\n\nEmbeddings are numerical representations of text (or other media formats) that capture relationships between inputs. Text embeddings work by converting text into arrays of floating point numbers, called vectors. These vectors are designed to capture the meaning of the text. The length of the embedding array is called the vector's dimensionality. A passage of text might be represented by a vector containing hundreds of dimensions.\n\nEmbeddings capture semantic meaning and context, which results in text with similar meanings having \"closer\" embeddings. For example, the sentence \"I took my dog to the vet\" and \"I took my cat to the vet\" would have embeddings that are close to each other in the vector space.\n\nYou can use embeddings to compare different texts and understand how they relate. For example, if the embeddings of the text \"cat\" and \"dog\" are close together you can infer that these words are similar in meaning, context, or both. This enables a variety of common AI use cases.\n\nBefore you begin\n\nBefore calling the Gemini API, ensure you have your SDK of choice installed, and a Gemini API key configured and ready to use.\n\nGenerate embeddings\n\nUse the embedContent method to generate text embeddings:\n\nPython\nJavaScript\nGo\nREST\nfrom google import genai\n\nclient = genai.Client(api_key=\"GEMINI_API_KEY\")\n\nresult = client.models.embed_content(\n        model=\"gemini-embedding-exp-03-07\",\n        contents=\"What is the meaning of life?\")\n\nprint(result.embeddings)\n\n\nYou can also generate embeddings for multiple chunks at once by passing them in as a list of strings.\n\nTask types\n\nWhen building Retrieval Augmented Generation (RAG) systems, a common design is to use text embeddings to perform a similarity search. In some cases this can lead to degraded quality, because questions and their answers are not semantically similar. For example, a question like \"Why is the sky blue?\" and its answer \"The scattering of sunlight causes the blue color,\" have distinctly different meanings as statements, which means that a RAG system won't automatically recognize their relation.\n\nTask types enable you to generate optimized embeddings for specific tasks, saving you time and cost and improving performance.\n\nPython\nJavaScript\nREST\nfrom google import genai\nfrom google.genai import types\n\nclient = genai.Client(api_key=\"GEMINI_API_KEY\")\n\nresult = client.models.embed_content(\n        model=\"gemini-embedding-exp-03-07\",\n        contents=\"What is the meaning of life?\",\n        config=types.EmbedContentConfig(task_type=\"SEMANTIC_SIMILARITY\")\n)\nprint(result.embeddings)\n\nSupported task types\nTask type\tDescription\nSEMANTIC_SIMILARITY\tUsed to generate embeddings that are optimized to assess text similarity.\nCLASSIFICATION\tUsed to generate embeddings that are optimized to classify texts according to preset labels.\nCLUSTERING\tUsed to generate embeddings that are optimized to cluster texts based on their similarities.\nRETRIEVAL_DOCUMENT, RETRIEVAL_QUERY, QUESTION_ANSWERING, and FACT_VERIFICATION\tUsed to generate embeddings that are optimized for document search or information retrieval.\nCODE_RETRIEVAL_QUERY\tUsed to retrieve a code block based on a natural language query, such as sort an array or reverse a linked list. Embeddings of the code blocks are computed using RETRIEVAL_DOCUMENT.\nUse cases\n\nText embeddings are used in a variety of common AI use cases, such as:\n\nInformation retrieval: You can use embeddings to retrieve semantically similar text given a piece of input text.\n\nDocument search tutorialtask\n\nClustering: Comparing groups of embeddings can help identify hidden trends.\n\nEmbedding clustering tutorialbubble_chart\n\nVector database: As you take different embedding use cases to production, it is common to store embeddings in a vector database.\n\nVector database tutorialbolt\n\nClassification: You can train a model using embeddings to classify documents into categories.\n\nClassification tutorialtoken\n\nEmbedding models\n\nThe Gemini API offers three models that generate text embeddings:\n\ngemini-embedding-exp-03-07\ntext-embedding-004\nembedding-001\nWhat's next\n\nCheck out the embeddings quickstart notebook.\n\nSend feedback\n\nExcept as otherwise noted, the content of this page is licensed under the Creative Commons Attribution 4.0 License, and code samples are licensed under the Apache 2.0 License. For details, see the Google Developers Site Policies. Java is a registered trademark of Oracle and/or its affiliates.\n\nLast updated 2025-04-28 UTC.\n\nTerms\nPrivacy",
  "updatedAt": "2025-05-13T03:20:18.260Z"
}