{
  "url": "https://ai.google.dev/gemini-api/docs/files",
  "content": "Skip to main content\nSign in\nModels\nMore\nGemini API docs\nAPI Reference\nCookbook\nCommunity\nSolutions\nMore\nCode assistance\nMore\nShowcase\nMore\nCommunity\nMore\nGet started\nOverview\nQuickstart\nAPI keys\nLibraries\nOpenAI compatibility\nModels\nAll models\nPricing\nRate limits\nBilling info\nModel Capabilities\nText generation\nImage generation\nVideo generation\nLong context\nStructured output\nThinking\nFunction calling\nDocument understanding\nImage understanding\nVideo understanding\nAudio understanding\nCode execution\nGrounding with Google Search\nGuides\nPrompt engineering\nLive API\nContext caching\nFiles API\nToken counting\nFine-tuning\nEmbeddings\nSafety\nResources\nMigrate to Gen AI SDK\nRelease notes\nAPI troubleshooting\nAI Studio\nCloud\nPolicies\nTerms of service\nAvailable regions\nAdditional usage polices\nIntroducing Gemini 2.5 Flash, Veo 2, and updates to the Live API Learn more\nHome\nGemini API\nModels\nSend feedback\nFiles API\nOn this page\nUpload a file\nGet metadata for a file\nList uploaded files\nDelete uploaded files\nUsage info\nFile prompting strategies\nBe specific in your instructions\nAdd a few examples\n\nThe Gemini family of artificial intelligence (AI) models is built to handle various types of input data, including text, images, and audio. Since these models can handle more than one type or mode of data, the Gemini models are called multimodal models or explained as having multimodal capabilities.\n\nThis guide shows you how to work with media files using the Files API. The basic operations are the same for audio files, images, videos, documents, and other supported file types.\n\nFor file prompting guidance, check out the File prompt guide section.\n\nUpload a file\n\nYou can use the Files API to upload a media file. Always use the Files API when the total request size (including the files, text prompt, system instructions, etc.) is larger than 20 MB.\n\nThe following code uploads a file and then uses the file in a call to generateContent.\n\nPython\nJavaScript\nGo\nREST\nfrom google import genai\n\nclient = genai.Client(api_key=\"GOOGLE_API_KEY\")\n\nmyfile = client.files.upload(file=\"path/to/sample.mp3\")\n\nresponse = client.models.generate_content(\n    model=\"gemini-2.0-flash\", contents=[\"Describe this audio clip\", myfile]\n)\n\nprint(response.text)\n\nGet metadata for a file\n\nYou can verify that the API successfully stored the uploaded file and get its metadata by calling files.get.\n\nPython\nJavaScript\nGo\nREST\nmyfile = client.files.upload(file='path/to/sample.mp3')\nfile_name = myfile.name\nmyfile = client.files.get(name=file_name)\nprint(myfile)\n\nList uploaded files\n\nYou can upload multiple files using the Files API. The following code gets a list of all the files uploaded:\n\nPython\nJavaScript\nGo\nREST\nprint('My files:')\nfor f in client.files.list():\n    print(' ', f.name)\n\nDelete uploaded files\n\nFiles are automatically deleted after 48 hours. You can also manually delete an uploaded file:\n\nPython\nJavaScript\nGo\nREST\nmyfile = client.files.upload(file='path/to/sample.mp3')\nclient.files.delete(name=myfile.name)\n\nUsage info\n\nYou can use the Files API to upload and interact with media files. The Files API lets you store up to 20 GB of files per project, with a per-file maximum size of 2 GB. Files are stored for 48 hours. During that time, you can use the API to get metadata about the files, but you can't download the files. The Files API is available at no cost in all regions where the Gemini API is available.\n\nFile prompting strategies\n\nThis section provides guidance and best practices for using media files with prompts for the Gemini API.\n\nBeing able to use various types of data in your prompts gives you more flexibility in terms of what tasks you can tackle with the Gemini API. For example, you can send the model a photo of a delicious meal and ask it to write a short blog about the meal.\n\nPrompt\tResponse\n\n\nWrite a short, engaging blog post based on this picture. It should include a description of the meal in the photo and talk about my journey meal prepping.\n\n\n\t\n\nMeal prepping is a great way to save time and money, and it can also help you to eat healthier. This meal is a great example of a healthy and delicious meal that can be easily prepped ahead of time.\n\nThis meal features brown rice, roasted vegetables, and chicken teriyaki. The brown rice is a healthy and complex carbohydrate that will give you sustained energy. The roasted vegetables are a great way to get your daily dose of vitamins and minerals, and the chicken teriyaki is a delicious and protein-rich option.\n\nThis meal is also very easy to prepare. Simply cook the brown rice, roast the vegetables, and cook the chicken teriyaki. Once everything is cooked, divide it into meal prep containers and store them in the refrigerator. You can then grab a container and go on busy mornings!\n\nIf you're looking for a healthy and delicious meal that can be easily prepped ahead of time, this meal is a great option. It's packed with nutrients and flavor, and it's sure to keep you feeling full and satisfied.\n\nHere's to healthy and delicious meal prepping!\n\nIf you are having trouble getting the output you want from prompts that use media files, there are some strategies that can help you get the results you want. The following sections provide design approaches and troubleshooting tips for improving prompts that use multimodal input.\n\nYou can improve your multimodal prompts by following these best practices:\n\nPrompt design fundamentals\nBe specific in your instructions: Craft clear and concise instructions that leave minimal room for misinterpretation.\nAdd a few examples to your prompt: Use realistic few-shot examples to illustrate what you want to achieve.\nBreak it down step-by-step: Divide complex tasks into manageable sub-goals, guiding the model through the process.\nSpecify the output format: In your prompt, ask for the output to be in the format you want, like markdown, JSON, HTML and more.\nPut your image first for single-image prompts: While Gemini can handle image and text inputs in any order, for prompts containing a single image, it might perform better if that image (or video) is placed before the text prompt. However, for prompts that require images to be highly interleaved with texts to make sense, use whatever order is most natural.\nTroubleshooting your multimodal prompt\nIf the model is not drawing information from the relevant part of the image: Drop hints with which aspects of the image you want the prompt to draw information from.\nIf the model output is too generic (not tailored enough to the image/video input): At the start of the prompt, try asking the model to describe the image(s) or video before providing the task instruction, or try asking the model to refer to what's in the image.\nTo troubleshoot which part failed: Ask the model to describe the image, or ask the model to explain its reasoning, to gauge the model's initial understanding.\nIf your prompt results in hallucinated content: Try dialing down the temperature setting or asking the model for shorter descriptions so that it's less likely to extrapolate additional details.\nTuning the sampling parameters: Experiment with different temperature settings and top-k selections to adjust the model's creativity.\nBe specific in your instructions\n\nPrompts have the most success when they are clear and detailed. If you have a specific output in mind, it's better to include that requirement in the prompt to ensure you get the output you want.\n\nFor this image of an airport board, asking the model to just \"describe this image\" could generate a general description. If you need the model to parse the time and city from the image, you can include that request directly in your prompt.\n\nPrompt\tModel response\n\n\nDescribe this image.\n\n\t\n\nThe image shows an airport arrivals and departures board.\n\nUpdated prompt\tImproved response\n\n\nParse the time and city from the airport board shown in this image into a list.\n\n\t\n\n10:50 Moscow\n11:05 Edinburgh\n11:05 London\n11:10 Bucharest\n11:30 Kiev\n11:35 Dublin\n11:45 East Midlands\n12:15 Sofia\n12:30 London\n12:30 Newcastle\n12:40 St Petersburg\n12:40 London\n12:45 Manchester\n\nAdd a few examples\n\nThe Gemini model can accept multiple inputs which it can use as examples to understand the output you want. Adding these examples can help the model identify the patterns and apply the relationship between the given images and responses to the new example. This is also called \"few-shot\" learning.\n\nIn the example below, the initial output is written in sentence form, and also contains the country (Brazil). Suppose you want the output in a different format or style, and you want only the city, not the country. Adding few-shot examples to your prompt can steer the model to respond in the way you want.\n\nPrompt\tModel response\n\n\nDetermine the city along with the landmark.\n\n\t\n\nThe landmark is the Christ the Redeemer statue in Rio de Janeiro, Brazil.\n\nUpdated prompt\tImproved response\n\n\nDetermine the city along with the landmark.\n\n\t\n\ncity: Rome, landmark: the Colosseum.\n\n\n\t\n\ncity: Beijing, landmark: Forbidden City\n\n\n\t\n\ncity: Rio de Janeiro, landmark: Christ the Redeemer statue\n\nBreak it down step-by-step\n\nFor complex tasks like the ones that require both visual understanding and reasoning, it can be helpful to split the task into smaller, more straightforward steps. Alternatively, it could also be effective if you directly ask the model to “think step by step” in your prompt.\n\nPrompt\tModel response\n\n\nWhen will I run out of toilet paper?\n\n\t\n\nSoon, you only have 3 rolls left.\n\nUpdated prompt\tImproved response\n\n\n1. First, count how many toilet paper rolls are in this picture.\n2. Then, determine how much toilet paper a typical person uses per day.\n3. Calculate how long these rolls of toilet paper will last.\n\n\t\n\n1. There are 3 rolls of toilet paper in this picture.\n2. A typical person uses about 20 sheets of toilet paper per day.\n3. If each roll contains 200 sheets, then each roll will last for about 10 days. Therefore, the 3 rolls will last for about a month.\n\nMath problems or other types of word problems are great candidates for asking the model to think step-by-step.\n\nPrompt\tResponse\n\n\nWhat is the 4th term in the sequence?\n\n\t\n\n-135\n\nThe response from the model is incorrect. Some ways to improve this is to ask the model to parse the problem before answering the prompt.\n\nPrompt\tResponse\n\n\nParse the formula in the image first.\n\nThen based on the formula, answer \"what's the 4th term in the sequence?\".\n\n\t\n\nClick to expand the result\n\nThis model response is correct - now to make the response even more streamlined, you can ask the model to to think step-by-step.\n\nUpdated prompt\tImproved response\n\n\nWhat is the 4th term in the sequence? Think step by step.\n\n\t\n\nThe first term is 15.\n\nThe second term is b(1) * (-3) = 15 * (-3) = -45.\n\nThe third term is b(2) * (-3) = -45 * (-3) = 135.\n\nThe fourth term is b(3) * (-3) = 135 * (-3) = -405.\n\nSpecify the output format\n\nA common problem is the need for model output to be in a certain format (e.g. markdown, JSON, HTML), especially if the model output needs to be ingested by a downstream task. You can try to produce output in that format by instructing the model to do so within the prompt. Below are two examples:\n\nPrompt\tModel response\n\n\nParse the table in this image into markdown format\n\n\t\n\n| Subject | Status | Time | Start date | Due on |\n\n| ------- | ------ | ---- | --------- | ------ |\n\n| Math | Done | 1.5 hrs | 11/29/2023 | 12/1/2023 |\n\n| Geography | Done | 30 min | 12/2/2023 | 12/4/2023 |\n\n| Physics | In progress | 2 hrs | 12/3/2023 | 12/5/2023 |\n\n| Biology | Not started | 6 hrs | 11/2/2016 | 12/6/2023 |\n\nPrompt\tModel response\n\n\nProvide a list of all the following attributes:\n\ningredients, type of cuisine, vegetarian or not, in JSON format\n\n\t\n\n```json```\n\n{\n\n\"ingredients\": [\n\n\"rice\",\n\n\"shrimp\",\n\n\"clams\",\n\n\"mussels\",\n\n\"peas\",\n\n\"tomatoes\",\n\n\"onions\",\n\n\"garlic\",\n\n\"olive oil\",\n\n\"paprika\",\n\n\"salt\",\n\n\"pepper\"\n\n],\n\n\"type of cuisine\": \"Spanish\",\n\n\"vegetarian\": false\n\nPut your image first for single-image prompts\n\nWhile Gemini can interpret image and text in any order within a prompt, placing a single image before the text prompt might lead to better results. In the following samples, you'll notice the image comes first before the text in each prompt.\n\nTroubleshooting your multimodal prompt\n\nYou might need to troubleshoot your prompt if you are not getting a helpful response. Here are a few strategies you could try.\n\nIf the model is not drawing information from the relevant part of the image\n\nTo get a more specific response, you can point out which aspects of the image you want the prompt to draw information from to inform its response.\n\nPrompt\tModel response\n\n\nHow many days will these diapers last a baby?\n\n\t\n\nThe diapers will last for 198 days before they run out.\n\nUpdated prompt\tImproved response\n\n\nHow long will these diapers last before I run out?\n\nUse the weight shown on the box to determine the child's age, and use the total number of diapers in the box.\n\nDivide the total number by how many diapers the child goes through per day.\n\n\t\n\nThe box contains 198 diapers. The box states the diapers are for a child weighing 22-37 lbs.\n\nThe average child in this weight range is likely between 1 and 2 years old.\n\nA 2-year-old typically goes through 6 diapers per day, therefore, the diapers will last around 33 days (198/6).\n\nIf the model output is too generic and not tailored enough to the image input\n\nTo help the model tailor its response to the image(s), try asking it to describe the images before performing its reasoning task.\n\nPrompt\tModel response\n   \n\nWhat is in common between these images?\n\n\t\n\nAll four images are examples of landscape photography.\n\nUpdated prompt\tImproved response\n   \n\nFirst, describe what's in each image in detail. What's in common between these images?\n\n\t\n\nThe first image shows a person packing a suitcase. The second image shows an empty hallway in a shopping mall. The third image shows a roll of toilet paper. The fourth image shows a dark and stormy sea.\n\nThe commonality between these images is that they are all examples of liminal spaces. Liminal spaces are places or situations that are in between two other places or situations. They are often characterized by a sense of uncertainty or ambiguity.\n\nThe first image shows the person in between being at home and being on a trip. The second image shows the hallway in between two stores. The third image is of toilet paper, which can represent a bathroom. A bathroom is a transitional space between private and public realms. It's a place where we prepare ourselves to enter or leave the outside world.\n\nThe fourth image shows the sea in between being calm and being stormy.\n\nLiminal spaces can be both exciting and unsettling. They can be a place of new beginning or a place of endings. They can be a place of reflection or a place of action.\n\nYou can also try explicitly asking the model to refer to what's in the image.\n\nUpdated prompt\tImproved response\n   \n\nWhat is in common between these images? Refer to what's in the images in your response.\n\n\t\n\nAll of the images are related to travel. The first image shows a person packing a suitcase, the second image shows an empty hallway in a shopping mall, the third image shows a stack of toilet paper, and the fourth image shows a dark and stormy sea.\n\nThese images are all related to travel because they are all things that people need or use when they travel. The first image shows a person packing a suitcase, which is something that people do when they are going on a trip. The second image shows an empty hallway in a shopping mall, which is a place where people often go to buy things for their trips. The third image shows a stack of toilet paper, which is something that people often use when they are traveling. The fourth image shows a dark and stormy sea, which is something that people often encounter when they are traveling.\n\nThe same tips work for creative output from images. In the following example with the rabbit, explicitly asking the model to include aspects from the image can improve the output.\n\nPrompt\tModel response\n\n\nCan you write me a poem about this image?\n\n\t\n\nLittle bunny, so soft and brown,\nHopping through the field, up and down.\nYour ears so long, your tail so small,\nYou're the cutest creature of them all.\n\nYou nibble on the grass, so green and sweet,\nAnd hop away when you see me.\nBut I'll always be your friend,\nLittle bunny, until the very end.\n\nUpdated prompt\tImproved response\n\n\nCan you write me a descriptive and dramatic poem about this image and include the location?\n\n\t\n\nLittle bunny on the green,\nEars so long, so keen.\nWhat do you see out there,\nIn the distance, where you stare?\n\nIs it the ocean blue,\nSparkling in the sun's hue?\nOr the waves that crash and roar,\nA rhythm that you adore?\n\nLittle bunny, tell me true,\nWhat captures your attention so?\nIs it the salty breeze,\nOr the seagulls' cries that please?\n\nPerhaps it's the vastness of it all,\nA world so big and small.\nA place where dreams can roam,\nAnd adventures can be sown.\n\nLittle bunny, I wonder what you dream,\nAs you sit on the grass, so serene.\nDo you yearn to explore the deep,\nOr stay on land, where you can leap?\n\nWhatever it may be, little bunny,\nKeep that spark of wonder burning brightly.\nFor in your dreams and aspirations,\nLies a world waiting for your creation.\n\nTroubleshooting which part of the prompt failed\n\nIt can be hard to know whether a prompt failed because the model didn't understand the image to begin with, or if it did understand the image but did not perform the correct reasoning steps afterward. To disambiguate between those reasons, ask the model to describe what's in the image.\n\nIn the following example, if the model responds with a snack that seems surprising when paired with tea (e.g. popcorn), you can first troubleshoot to determine whether the model correctly recognized that the image contains tea.\n\nPrompt\tPrompt for troubleshooting\n\n\nWhat's a snack I can make in 1 minute that would go well with this?\n\n\t\n\nDescribe what's in this image.\n\nAnother strategy is to ask the model to explain its reasoning. That can help you narrow down which part of the reasoning broke down, if any.\n\nPrompt\tPrompt for troubleshooting\n\n\nWhat's a snack I can make in 1 minute that would go well with this?\n\n\t\n\nWhat's a snack I can make in 1 minute that would go well with this? Please explain why.\n\nWhat's next\nTry writing your own multimodal prompts using Google AI Studio.\nFor information on using the Gemini Files API for uploading media files and including them in your prompts, see the Vision, Audio, and Document processing guides.\nFor more guidance on prompt design, like tuning sampling parameters, see the Prompt strategies page.\nSend feedback\n\nExcept as otherwise noted, the content of this page is licensed under the Creative Commons Attribution 4.0 License, and code samples are licensed under the Apache 2.0 License. For details, see the Google Developers Site Policies. Java is a registered trademark of Oracle and/or its affiliates.\n\nLast updated 2025-05-12 UTC.\n\nTerms\nPrivacy",
  "updatedAt": "2025-05-13T03:19:15.457Z"
}