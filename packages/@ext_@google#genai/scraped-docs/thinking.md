{
  "url": "https://ai.google.dev/gemini-api/docs/thinking",
  "content": "Skip to main content\nSign in\nModels\nMore\nGemini API docs\nAPI Reference\nCookbook\nCommunity\nSolutions\nMore\nCode assistance\nMore\nShowcase\nMore\nCommunity\nMore\nGet started\nOverview\nQuickstart\nAPI keys\nLibraries\nOpenAI compatibility\nModels\nAll models\nPricing\nRate limits\nBilling info\nModel Capabilities\nText generation\nImage generation\nVideo generation\nLong context\nStructured output\nThinking\nFunction calling\nDocument understanding\nImage understanding\nVideo understanding\nAudio understanding\nCode execution\nGrounding with Google Search\nGuides\nPrompt engineering\nLive API\nContext caching\nFiles API\nToken counting\nFine-tuning\nEmbeddings\nSafety\nResources\nMigrate to Gen AI SDK\nRelease notes\nAPI troubleshooting\nAI Studio\nCloud\nPolicies\nTerms of service\nAvailable regions\nAdditional usage polices\nIntroducing Gemini 2.5 Flash, Veo 2, and updates to the Live API Learn more\nHome\nGemini API\nModels\nSend feedback\nGemini thinking\nOn this page\nUse thinking models\nSend a basic request\nSet budget on thinking models\nUse tools with thinking models\nBest practices\nDebugging and steering\nTask complexity\nWhat's next?\n\nThe Gemini 2.5 series models use an internal \"thinking process\" during response generation. This process contributes to their improved reasoning capabilities and helps them use multi-step planning to solve complex tasks. This makes these models especially good at coding, advanced mathematics, data analysis, and other tasks that require planning or thinking.\n\nTry Gemini 2.5 Flash Preview in Google AI Studio\n\nThis guide shows you how to work with Gemini's thinking capabilities using the Gemini API.\n\nUse thinking models\n\nModels with thinking capabilities are available in Google AI Studio and through the Gemini API. Thinking is on by default in both the API and AI Studio because the 2.5 series models have the ability to automatically decide when and how much to think based on the prompt. For most use cases, it's beneficial to leave thinking on. But if you want to to turn thinking off, you can do so by setting the thinkingBudget parameter to 0.\n\nNote: Only Gemini 2.5 Flash supports thinking budgets right now, 2.5 Pro support is coming soon!\nSend a basic request\nPython\nJavaScript\nGo\nREST\nfrom google import genai\n\nclient = genai.Client(api_key=\"GOOGLE_API_KEY\")\nprompt = \"Explain the concept of Occam's Razor and provide a simple, everyday example.\"\nresponse = client.models.generate_content(\n    model=\"gemini-2.5-flash-preview-04-17\",\n    contents=prompt\n)\n\nprint(response.text)\n\nSet budget on thinking models\n\nThe thinkingBudget parameter gives the model guidance on the number of thinking tokens it can use when generating a response. A greater number of tokens is typically associated with more detailed thinking, which is needed for solving more complex tasks. thinkingBudget must be an integer in the range 0 to 24576. Setting the thinking budget to 0 disables thinking.\n\nDepending on the prompt, the model might overflow or underflow the token budget.\n\nPython\nJavaScript\nREST\nfrom google import genai\nfrom google.genai import types\n\nclient = genai.Client()\n\nresponse = client.models.generate_content(\n    model=\"gemini-2.5-flash-preview-04-17\",\n    contents=\"Explain the Occam's Razor concept and provide everyday examples of it\",\n    config=types.GenerateContentConfig(\n        thinking_config=types.ThinkingConfig(thinking_budget=1024)\n    ),\n)\n\nprint(response.text)\n\nUse tools with thinking models\n\nYou can combine your use of the thinking models with any of Gemini's tools and capabilities to perform actions beyond generating text. This allows them to interact with external systems, execute code, or access real-time information, incorporating the results into their reasoning and final response.\n\nThe search tool allows the model to query external search engines to find up-to-date information or information beyond its training data. This is useful for questions about recent events or highly specific topics.\n\nThe code execution tool enables the model to generate and run Python code to perform calculations, manipulate data, or solve problems that are best handled algorithmically. The model receives the code's output and can use it in its response.\n\nWith structured output, you can constrain Gemini to respond with JSON, a structured output format suitable for automated processing. This is particularly useful for integrating the model's output into applications.\n\nFunction calling connects the thinking model to external tools and APIs, so it can reason around when to call the right function and what parameters to provide.\n\nBest practices\n\nThis section includes some guidance for using thinking models efficiently. As always, following our prompting guidance and best practices will get you the best results.\n\nDebugging and steering\n\nReview reasoning: When you're not getting your expected response from the thinking models, it can help to carefully analyze Gemini's reasoning process. You can see how it broke down the task and arrived at its conclusion, and use that information to correct towards the right results.\n\nProvide Guidance in Reasoning: If you're hoping for a particularly lengthy output, you may want to provide guidance in your prompt to constrain the amount of thinking the model uses. This lets you reserve more of the token output for your response.\n\nTask complexity\nEasy Tasks (Thinking could be OFF): For straightforward requests, complex reasoning isn't required such as straightforward fact retrieval or classification, thinking is not required. Examples include:\n\"Where was DeepMind founded?\"\n\"Is this email asking for a meeting or just providing information?\"\nMedium Tasks (Default/Some Thinking): Many common requests benefit from a degree of step-by-step processing or deeper understanding. Gemini can flexibly use thinking capability for tasks like:\nAnalogize photosynthesis and growing up.\nCompare and contrast electric cars and hybrid cars.\nHard Tasks (Maximum Thinking Capability): For truly complex challenges, the AI needs to engage its full reasoning and planning capabilities, often involving many internal steps before providing an answer. Examples include:\nSolve problem 1 in AIME 2025: Find the sum of all integer bases b > 9 for which 17b is a divisor of 97b.\nWrite Python code for a web application that visualizes real-time stock market data, including user authentication. Make it as efficient as possible.\nWhat's next?\nTry Gemini 2.5 Pro Preview in Google AI Studio.\nFor more info about Gemini 2.5 Pro Preview and Gemini Flash 2.0 Thinking, see the model page.\nTry more examples in the Thinking cookbook.\nSend feedback\n\nExcept as otherwise noted, the content of this page is licensed under the Creative Commons Attribution 4.0 License, and code samples are licensed under the Apache 2.0 License. For details, see the Google Developers Site Policies. Java is a registered trademark of Oracle and/or its affiliates.\n\nLast updated 2025-05-12 UTC.\n\nTerms\nPrivacy",
  "updatedAt": "2025-05-13T03:14:01.914Z"
}