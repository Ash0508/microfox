{
  "url": "https://ai.google.dev/gemini-api/docs/text-generation",
  "content": "Skip to main content\nSign in\nModels\nMore\nGemini API docs\nAPI Reference\nCookbook\nCommunity\nSolutions\nMore\nCode assistance\nMore\nShowcase\nMore\nCommunity\nMore\nGet started\nOverview\nQuickstart\nAPI keys\nLibraries\nOpenAI compatibility\nModels\nAll models\nPricing\nRate limits\nBilling info\nModel Capabilities\nText generation\nImage generation\nVideo generation\nLong context\nStructured output\nThinking\nFunction calling\nDocument understanding\nImage understanding\nVideo understanding\nAudio understanding\nCode execution\nGrounding with Google Search\nGuides\nPrompt engineering\nLive API\nContext caching\nFiles API\nToken counting\nFine-tuning\nEmbeddings\nSafety\nResources\nMigrate to Gen AI SDK\nRelease notes\nAPI troubleshooting\nAI Studio\nCloud\nPolicies\nTerms of service\nAvailable regions\nAdditional usage polices\nIntroducing Gemini 2.5 Flash, Veo 2, and updates to the Live API Learn more\nHome\nGemini API\nModels\nSend feedback\nText generation\nOn this page\nSystem instructions and configurations\nMultimodal inputs\nStreaming responses\nMulti-turn conversations (Chat)\nSupported models\nBest practices\nPrompting tips\nStructured output\n\nThe Gemini API can generate text output from various inputs, including text, images, video, and audio, leveraging Gemini models.\n\nHere's a basic example that takes a single text input:\n\nPython\nJavaScript\nGo\nREST\nApps Script\nfrom google import genai\n\nclient = genai.Client(api_key=\"GEMINI_API_KEY\")\n\nresponse = client.models.generate_content(\n    model=\"gemini-2.0-flash\",\n    contents=[\"How does AI work?\"]\n)\nprint(response.text)\n\n\nSystem instructions and configurations\n\nYou can guide the behavior of Gemini models with system instructions. To do so, pass a GenerateContentConfig object.\n\nPython\nJavaScript\nGo\nREST\nApps Script\nfrom google import genai\nfrom google.genai import types\n\nclient = genai.Client(api_key=\"GEMINI_API_KEY\")\n\nresponse = client.models.generate_content(\n    model=\"gemini-2.0-flash\",\n    config=types.GenerateContentConfig(\n        system_instruction=\"You are a cat. Your name is Neko.\"),\n    contents=\"Hello there\"\n)\n\nprint(response.text)\n\n\nThe GenerateContentConfig object also lets you override default generation parameters, such as temperature.\n\nPython\nJavaScript\nGo\nREST\nApps Script\nfrom google import genai\nfrom google.genai import types\n\nclient = genai.Client(api_key=\"GEMINI_API_KEY\")\n\nresponse = client.models.generate_content(\n    model=\"gemini-2.0-flash\",\n    contents=[\"Explain how AI works\"],\n    config=types.GenerateContentConfig(\n        max_output_tokens=500,\n        temperature=0.1\n    )\n)\nprint(response.text)\n\n\nRefer to the GenerateContentConfig in our API reference for a complete list of configurable parameters and their descriptions.\n\nMultimodal inputs\n\nThe Gemini API supports multimodal inputs, allowing you to combine text with media files. The following example demonstrates providing an image:\n\nPython\nJavaScript\nGo\nREST\nApps Script\nfrom PIL import Image\nfrom google import genai\n\nclient = genai.Client(api_key=\"GEMINI_API_KEY\")\n\nimage = Image.open(\"/path/to/organ.png\")\nresponse = client.models.generate_content(\n    model=\"gemini-2.0-flash\",\n    contents=[image, \"Tell me about this instrument\"]\n)\nprint(response.text)\n\n\nFor alternative methods of providing images and more advanced image processing, see our image understanding guide. The API also supports document, video, and audio inputs and understanding.\n\nStreaming responses\n\nBy default, the model returns a response only after the entire generation process is complete.\n\nFor more fluid interactions, use streaming to receive GenerateContentResponse instances incrementally as they're generated.\n\nPython\nJavaScript\nGo\nREST\nApps Script\nfrom google import genai\n\nclient = genai.Client(api_key=\"GEMINI_API_KEY\")\n\nresponse = client.models.generate_content_stream(\n    model=\"gemini-2.0-flash\",\n    contents=[\"Explain how AI works\"]\n)\nfor chunk in response:\n    print(chunk.text, end=\"\")\n\nMulti-turn conversations (Chat)\n\nOur SDKs provide functionality to collect multiple rounds of prompts and responses into a chat, giving you an easy way to keep track of the conversation history.\n\nNote: Chat functionality is only implemented as part of the SDKs. Behind the scenes, it still uses the generateContent API.\nPython\nJavaScript\nGo\nREST\nApps Script\nfrom google import genai\n\nclient = genai.Client(api_key=\"GEMINI_API_KEY\")\nchat = client.chats.create(model=\"gemini-2.0-flash\")\n\nresponse = chat.send_message(\"I have 2 dogs in my house.\")\nprint(response.text)\n\nresponse = chat.send_message(\"How many paws are in my house?\")\nprint(response.text)\n\nfor message in chat.get_history():\n    print(f'role - {message.role}',end=\": \")\n    print(message.parts[0].text)\n\n\nStreaming can also be used for multi-turn conversations.\n\nPython\nJavaScript\nGo\nREST\nApps Script\nfrom google import genai\n\nclient = genai.Client(api_key=\"GEMINI_API_KEY\")\nchat = client.chats.create(model=\"gemini-2.0-flash\")\n\nresponse = chat.send_message_stream(\"I have 2 dogs in my house.\")\nfor chunk in response:\n    print(chunk.text, end=\"\")\n\nresponse = chat.send_message_stream(\"How many paws are in my house?\")\nfor chunk in response:\n    print(chunk.text, end=\"\")\n\nfor message in chat.get_history():\n    print(f'role - {message.role}', end=\": \")\n    print(message.parts[0].text)\n\nSupported models\n\nAll models in the Gemini family support text generation. To learn more about the models and their capabilities, visit the Models page.\n\nBest practices\nPrompting tips\n\nFor basic text generation, a zero-shot prompt often suffices without needing examples, system instructions or specific formatting.\n\nFor more tailored outputs:\n\nUse System instructions to guide the model.\nProvide few example inputs and outputs to guide the model. This is often referred to as few-shot prompting.\nConsider fine-tuning for advanced use cases.\n\nConsult our prompt engineering guide for more tips.\n\nStructured output\n\nIn some cases, you may need structured output, such as JSON. Refer to our structured output guide to learn how.\n\nWhat's next\nTry the Gemini API getting started Colab.\nExplore Gemini's image, video, audio and document understanding capabilities.\nLearn about multimodal file prompting strategies.\nSend feedback\n\nExcept as otherwise noted, the content of this page is licensed under the Creative Commons Attribution 4.0 License, and code samples are licensed under the Apache 2.0 License. For details, see the Google Developers Site Policies. Java is a registered trademark of Oracle and/or its affiliates.\n\nLast updated 2025-05-09 UTC.\n\nTerms\nPrivacy",
  "updatedAt": "2025-05-13T03:12:09.150Z"
}