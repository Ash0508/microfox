{
  "url": "https://ai.google.dev/gemini-api/docs/usage-policies",
  "content": "Skip to main content\nSign in\nModels\nMore\nGemini API docs\nAPI Reference\nCookbook\nCommunity\nSolutions\nMore\nCode assistance\nMore\nShowcase\nMore\nCommunity\nMore\nGet started\nOverview\nQuickstart\nAPI keys\nLibraries\nOpenAI compatibility\nModels\nAll models\nPricing\nRate limits\nBilling info\nModel Capabilities\nText generation\nImage generation\nVideo generation\nLong context\nStructured output\nThinking\nFunction calling\nDocument understanding\nImage understanding\nVideo understanding\nAudio understanding\nCode execution\nGrounding with Google Search\nGuides\nPrompt engineering\nLive API\nContext caching\nFiles API\nToken counting\nFine-tuning\nEmbeddings\nSafety\nResources\nMigrate to Gen AI SDK\nRelease notes\nAPI troubleshooting\nAI Studio\nCloud\nPolicies\nTerms of service\nAvailable regions\nAdditional usage polices\nIntroducing Gemini 2.5 Flash, Veo 2, and updates to the Live API Learn more\nHome\nGemini API\nModels\nSend feedback\nAdditional usage policies\nOn this page\nAbuse monitoring\nHow We Monitor for Misuse\nHow We Handle Data\nHow We Investigate Potential Issues\nWorking with You on Policy Compliance\nScope\nInline Preference Voting\nWhy are we doing this?\n\nThis page includes additional usage policies for the Gemini API.\n\nAbuse monitoring\n\nGoogle is committed to the responsible development and use of AI. To ensure the safety and integrity of the Gemini API, we have created these policy guidelines. By using the Gemini API, you agree to the following guidelines, the Gemini API Additional Terms of Service and Generative AI Prohibited Use Policy.\n\nHow We Monitor for Misuse\n\nGoogle's Trust and Safety Team employs a combination of automated and manual processes to detect potential misuse of the Gemini API and enforce our policies.\n\nAutomated Detection: Automated systems scan API usage for violations of our Prohibited Use Policy, such as hate speech, harassment, sexually explicit content, and dangerous content.\nManual Detection: If a project consistently exhibits suspicious activity, it may be flagged for manual review by authorized Google personnel.\nHow We Handle Data\n\nTo help with abuse monitoring, Google retains the following data for fifty-five (55) days:\n\nPrompts: The text prompts you submit to the API.\nContextual Information: Any additional context you provide with your prompts.\nOutput: The responses generated by the Gemini API.\nHow We Investigate Potential Issues\n\nWhen prompts or model outputs are flagged by safety filters and abuse detection systems described above, authorized Google employees may assess the flagged content, and either confirm or correct the classification or determination based on predefined guidelines and policies. Data can be accessed for human review only by authorized Google employees via an internal governance assessment and review management platform. When data is logged for abuse monitoring, it is used solely for the purpose of policy enforcement and is not used to train or fine-tune any AI/ML models.\n\nWorking with You on Policy Compliance\n\nIf your use of Gemini doesn't align with our policies, we may take the following steps:\n\nGet in touch: We may reach out to you through email to understand your use case and explore ways to bring your usage into compliance.\nTemporary usage limits: We may limit your access to the Gemini API.\nTemporary suspension: We may temporarily pause your access to the Gemini API.\nAccount closure: As a last resort, and for serious violations, we may permanently close your access to the Gemini API and other Google services.\nScope\n\nThese policy guidelines apply to the use of the Gemini API and AI Studio.\n\nInline Preference Voting\n\nIn Google AI Studio, you might occasionally see a side-by-side comparison of two different responses to your prompt. This is part of our Inline Preference Voting system. You'll be asked to choose which response you prefer. This helps us understand which model outputs users find most helpful.\n\nWhy are we doing this?\n\nWe're constantly working to improve our AI models and services. Your feedback through Inline Preference Voting helps us provide, improve, and develop Google products and services and machine learning technologies, including Google's enterprise features, products and services, consistent with the Gemini API Additional Terms of Service and Privacy Policy.\n\nWhat data is included in Feedback?\n\nTo make informed decisions about our models, we collect certain data when you participate in Inline Preference Voting:\n\nPrompts and Responses: We record all prompts and responses, including any uploaded content, in the conversation you submitted feedback about. We also record the two response options that you selected from. This helps us understand the context of your preference.\nYour Vote: We record which response you preferred. This is the core of the feedback we're collecting.\nUsage Details: This includes information about which model generated the response and other technical and operational details about your usage of this feature.\nYour Privacy\n\nWe take your privacy seriously. Google takes steps to protect your privacy as part of this process. This includes disconnecting this data from your Google Account, API key, and Cloud project before reviewers see or annotate it. Do not submit feedback on conversations that include sensitive, confidential, or personal information.\n\nOpting Out\n\nYou'll have the option to skip the Inline Preference Voting when it appears.\n\nThank you for helping us improve Google AI Studio!\n\nSend feedback\n\nExcept as otherwise noted, the content of this page is licensed under the Creative Commons Attribution 4.0 License, and code samples are licensed under the Apache 2.0 License. For details, see the Google Developers Site Policies. Java is a registered trademark of Oracle and/or its affiliates.\n\nLast updated 2025-03-24 UTC.\n\nTerms\nPrivacy",
  "updatedAt": "2025-05-13T03:21:32.231Z"
}